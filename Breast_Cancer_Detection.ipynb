{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast_Cancer_Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrueStaples/Breast_Cancer_Detector/blob/master/Breast_Cancer_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sBcLs1tCdGc7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#You are embarking on a journey all across the world! As you come across a small impoverished village, you discoverd a great deal of the women were very sick. Based off reports of lumps being found on the women and other factors, you hypothesize it's breast cancer. After several calls, a couple of your close doctored collegues agree to offer assistance. Until they get there, your job is to construct a classifer that generalizes well to new data, so any women can be properly classified as having cancer or not.\n",
        "\n",
        "(the dataset being used is the Breast Cancer Wisconsin (Diagnostic) Data Set)\n"
      ]
    },
    {
      "metadata": {
        "id": "13BRISHKdhxv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Upload the CSV files which have already been pre-processed and pre-normalized"
      ]
    },
    {
      "metadata": {
        "id": "lwZrVTLLY3rP",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "22678f24-e146-4403-867a-c585d8792bcb"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "file = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d8ad94c7-490e-43f1-aa66-f9bd2c309d27\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d8ad94c7-490e-43f1-aa66-f9bd2c309d27\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving xtest.csv to xtest.csv\n",
            "Saving xtrain.csv to xtrain.csv\n",
            "Saving ytest.csv to ytest.csv\n",
            "Saving ytrain.csv to ytrain.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "noXwz7WmhJJV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Place the csv files into pandas dataframes to help with analysing your data easier"
      ]
    },
    {
      "metadata": {
        "id": "WfDLiJvuZRNf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#Training = CSV files \n",
        "inp_training = pd.read_csv('xtrain.csv', header=None)\n",
        "out_training = pd.read_csv('ytrain.csv', header=None)\n",
        "\n",
        "#Testing = CSV files\n",
        "inp_testing = pd.read_csv('xtest.csv', header=None)\n",
        "out_testing = pd.read_csv('ytest.csv', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4KdxSAid299",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a neural network for training our training data"
      ]
    },
    {
      "metadata": {
        "id": "GkwlfKCubZR2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "classifier = Sequential() #beginning of our ANN\n",
        "#4 layer NN\n",
        "classifier.add(Dense(units = 16, input_dim=30)) #16 neurons and 30 features\n",
        "classifier.add(Dense(units = 8, activation = 'relu')) #number if positive, 0 otherwise\n",
        "classifier.add(Dense(units = 6, activation = 'relu')) #number if positive, 0 otherwise\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid')) #1 or 0 w/.5 threshold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I0NZqYgIeLNu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once the NN is created, compile it with an optimizer and loss function. "
      ]
    },
    {
      "metadata": {
        "id": "vpETJtWBcTqL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#binary_crossentropy with 1 output is the same thing as categorical_crossentropy with two output nodes\n",
        "#binary_crossentropy: sigmoid activation, scalar target\n",
        "#categorical_crossentropy: softmax activation, one-hot encoded target\n",
        "#rmsprop is good with big datasets with redundant features\n",
        "classifier.compile(optimizer='rmsprop', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLCwWk0MeJVJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train your model using the 'fit' method!"
      ]
    },
    {
      "metadata": {
        "id": "BWXjLPHEcfzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3746
        },
        "outputId": "396d8ba2-92ae-45bd-e08a-395fafa47d10"
      },
      "cell_type": "code",
      "source": [
        "#pass in the training inputs and outputs\n",
        "#batch_size + epochs= trains 1 training example 100 times\n",
        "#classifier.fit(x_tra, y_train, batch_size= 1, epochs= 100)\n",
        "classifier.fit(inp_training, out_training, batch_size=1, epochs=100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 0.3897\n",
            "Epoch 2/100\n",
            "455/455 [==============================] - 1s 1ms/step - loss: 0.1030\n",
            "Epoch 3/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0791\n",
            "Epoch 4/100\n",
            "455/455 [==============================] - 0s 986us/step - loss: 0.0794\n",
            "Epoch 5/100\n",
            "455/455 [==============================] - 0s 980us/step - loss: 0.0780\n",
            "Epoch 6/100\n",
            "455/455 [==============================] - 0s 999us/step - loss: 0.0872\n",
            "Epoch 7/100\n",
            "455/455 [==============================] - 0s 999us/step - loss: 0.0835\n",
            "Epoch 8/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0931\n",
            "Epoch 9/100\n",
            "455/455 [==============================] - 0s 986us/step - loss: 0.0861\n",
            "Epoch 10/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0816\n",
            "Epoch 11/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0810\n",
            "Epoch 12/100\n",
            "455/455 [==============================] - 0s 996us/step - loss: 0.0705\n",
            "Epoch 13/100\n",
            "455/455 [==============================] - 0s 999us/step - loss: 0.0748\n",
            "Epoch 14/100\n",
            "455/455 [==============================] - 0s 977us/step - loss: 0.0825\n",
            "Epoch 15/100\n",
            "455/455 [==============================] - 0s 979us/step - loss: 0.0729\n",
            "Epoch 16/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0732\n",
            "Epoch 17/100\n",
            "455/455 [==============================] - 0s 982us/step - loss: 0.0713\n",
            "Epoch 18/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0674\n",
            "Epoch 19/100\n",
            "455/455 [==============================] - 0s 974us/step - loss: 0.0715\n",
            "Epoch 20/100\n",
            "455/455 [==============================] - 0s 974us/step - loss: 0.0817\n",
            "Epoch 21/100\n",
            "455/455 [==============================] - 0s 974us/step - loss: 0.0656\n",
            "Epoch 22/100\n",
            "455/455 [==============================] - 0s 986us/step - loss: 0.0816\n",
            "Epoch 23/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0703\n",
            "Epoch 24/100\n",
            "455/455 [==============================] - 0s 987us/step - loss: 0.0633\n",
            "Epoch 25/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0572\n",
            "Epoch 26/100\n",
            "455/455 [==============================] - 0s 982us/step - loss: 0.0797\n",
            "Epoch 27/100\n",
            "455/455 [==============================] - 0s 987us/step - loss: 0.0684\n",
            "Epoch 28/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0589\n",
            "Epoch 29/100\n",
            "455/455 [==============================] - 0s 997us/step - loss: 0.0818\n",
            "Epoch 30/100\n",
            "455/455 [==============================] - 0s 970us/step - loss: 0.0854\n",
            "Epoch 31/100\n",
            "455/455 [==============================] - 0s 991us/step - loss: 0.0729\n",
            "Epoch 32/100\n",
            "455/455 [==============================] - 0s 997us/step - loss: 0.0514\n",
            "Epoch 33/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0690\n",
            "Epoch 34/100\n",
            "455/455 [==============================] - 0s 980us/step - loss: 0.0535\n",
            "Epoch 35/100\n",
            "455/455 [==============================] - 0s 986us/step - loss: 0.0505\n",
            "Epoch 36/100\n",
            "455/455 [==============================] - 0s 973us/step - loss: 0.0552\n",
            "Epoch 37/100\n",
            "455/455 [==============================] - 0s 993us/step - loss: 0.0592\n",
            "Epoch 38/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0515\n",
            "Epoch 39/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0589\n",
            "Epoch 40/100\n",
            "455/455 [==============================] - 0s 989us/step - loss: 0.0472\n",
            "Epoch 41/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0598\n",
            "Epoch 42/100\n",
            "455/455 [==============================] - 0s 989us/step - loss: 0.0672\n",
            "Epoch 43/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0588\n",
            "Epoch 44/100\n",
            "455/455 [==============================] - 0s 988us/step - loss: 0.0653\n",
            "Epoch 45/100\n",
            "455/455 [==============================] - 0s 995us/step - loss: 0.0836\n",
            "Epoch 46/100\n",
            "455/455 [==============================] - 0s 972us/step - loss: 0.0713\n",
            "Epoch 47/100\n",
            "455/455 [==============================] - 0s 988us/step - loss: 0.0821\n",
            "Epoch 48/100\n",
            "455/455 [==============================] - 0s 993us/step - loss: 0.0787\n",
            "Epoch 49/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0797\n",
            "Epoch 50/100\n",
            "455/455 [==============================] - 0s 974us/step - loss: 0.0762\n",
            "Epoch 51/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0702\n",
            "Epoch 52/100\n",
            "455/455 [==============================] - 0s 990us/step - loss: 0.0742\n",
            "Epoch 53/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0750\n",
            "Epoch 54/100\n",
            "455/455 [==============================] - 0s 976us/step - loss: 0.0672\n",
            "Epoch 55/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0801\n",
            "Epoch 56/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0721\n",
            "Epoch 57/100\n",
            "455/455 [==============================] - 0s 966us/step - loss: 0.0843\n",
            "Epoch 58/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0760\n",
            "Epoch 59/100\n",
            "455/455 [==============================] - 0s 980us/step - loss: 0.0784\n",
            "Epoch 60/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0795\n",
            "Epoch 61/100\n",
            "455/455 [==============================] - 0s 984us/step - loss: 0.0679\n",
            "Epoch 62/100\n",
            "455/455 [==============================] - 0s 986us/step - loss: 0.0747\n",
            "Epoch 63/100\n",
            "455/455 [==============================] - 0s 999us/step - loss: 0.0721\n",
            "Epoch 64/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0700\n",
            "Epoch 65/100\n",
            "455/455 [==============================] - 0s 970us/step - loss: 0.0653\n",
            "Epoch 66/100\n",
            "455/455 [==============================] - 0s 985us/step - loss: 0.0798\n",
            "Epoch 67/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0705\n",
            "Epoch 68/100\n",
            "455/455 [==============================] - 0s 998us/step - loss: 0.0822\n",
            "Epoch 69/100\n",
            "455/455 [==============================] - 0s 993us/step - loss: 0.0780\n",
            "Epoch 70/100\n",
            "455/455 [==============================] - 0s 988us/step - loss: 0.0696\n",
            "Epoch 71/100\n",
            "455/455 [==============================] - 0s 988us/step - loss: 0.0693\n",
            "Epoch 72/100\n",
            "455/455 [==============================] - 0s 995us/step - loss: 0.0640\n",
            "Epoch 73/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0668\n",
            "Epoch 74/100\n",
            "455/455 [==============================] - 0s 975us/step - loss: 0.0721\n",
            "Epoch 75/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0794\n",
            "Epoch 76/100\n",
            "455/455 [==============================] - 0s 995us/step - loss: 0.0720\n",
            "Epoch 77/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0775\n",
            "Epoch 78/100\n",
            "455/455 [==============================] - 0s 998us/step - loss: 0.0723\n",
            "Epoch 79/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0717\n",
            "Epoch 80/100\n",
            "455/455 [==============================] - 0s 991us/step - loss: 0.0640\n",
            "Epoch 81/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0743\n",
            "Epoch 82/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0667\n",
            "Epoch 83/100\n",
            "455/455 [==============================] - 0s 996us/step - loss: 0.0783\n",
            "Epoch 84/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0732\n",
            "Epoch 85/100\n",
            "455/455 [==============================] - 0s 972us/step - loss: 0.0668\n",
            "Epoch 86/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0663\n",
            "Epoch 87/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0677\n",
            "Epoch 88/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0749\n",
            "Epoch 89/100\n",
            "455/455 [==============================] - 0s 989us/step - loss: 0.0713\n",
            "Epoch 90/100\n",
            "455/455 [==============================] - 0s 983us/step - loss: 0.0654\n",
            "Epoch 91/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0676\n",
            "Epoch 92/100\n",
            "455/455 [==============================] - 0s 988us/step - loss: 0.0675\n",
            "Epoch 93/100\n",
            "455/455 [==============================] - 0s 994us/step - loss: 0.0750\n",
            "Epoch 94/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0694\n",
            "Epoch 95/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0659\n",
            "Epoch 96/100\n",
            "455/455 [==============================] - 0s 971us/step - loss: 0.0779\n",
            "Epoch 97/100\n",
            "455/455 [==============================] - 0s 1000us/step - loss: 0.0682\n",
            "Epoch 98/100\n",
            "455/455 [==============================] - 0s 979us/step - loss: 0.0663\n",
            "Epoch 99/100\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.0654\n",
            "Epoch 100/100\n",
            "455/455 [==============================] - 0s 992us/step - loss: 0.0648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f84ff88f6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Fdi71cY2sW-s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice we got 6% loss meaning our model trained with a 94% accuracy! Now let's use the '.predict' method to see if our model generalizes well on our test data set. These outputs are probabilities so make them a 1 if the perceptrons turn out greater than or equal to .5 and 0 otherwise"
      ]
    },
    {
      "metadata": {
        "id": "KxPNnGh4ckwO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_predict = classifier.predict(inp_testing) \n",
        "test_predict = [1 if y>=.5 else 0 for y in test_predict] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1BhbVAFmsYVS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's print out the results of our testing!"
      ]
    },
    {
      "metadata": {
        "id": "ZAKXIgjjtbLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0ed42b0a-8458-48dd-e935-6e8f8571d0e8"
      },
      "cell_type": "code",
      "source": [
        "total_test_patients = 0\n",
        "right = 0\n",
        "wrong = 0\n",
        "\n",
        "for x in range(len(test_predict)): \n",
        "  total_test_patients=1+total_test_patients\n",
        "  if(out_testing.at[x,0] == test_predict[x]): #if the outputs of our test set at\n",
        "                                              #[var(x), 0] equals each var in \n",
        "                                              #our test prediction, then...\n",
        "    right=1+right\n",
        "  else:\n",
        "    wrong=1+wrong\n",
        "    \n",
        "    \n",
        "print(f'There were a total of {total_test_patients} patients that have been tested.')\n",
        "print(f'There were {right} patients correctly diagnosed.')\n",
        "print(f'There were {wrong} patients misdiagnosed.')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There were a total of 114 patients that have been tested.\n",
            "There were 111 patients correctly diagnosed.\n",
            "There were 3 patients misdiagnosed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OsxmsBOImo-t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#With only 3 people misdiagnosed, we were able to achieve a generalization of 97% accuracy with new data! Thank you for all your assistance! You helped saved the lives of hundreds of people! I can't wait to see what impact you make next!"
      ]
    }
  ]
}